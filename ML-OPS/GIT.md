***git*** - это распределённая система контроля версий. 

***Зам.*** версионирование может быть применено не только к коду, но и к любым файлам: заметкам, датасетам, рисункам, конфигурационным файлам и т.д.


| git                    | Без git, любая другая vcs |
| ---------------------- | ------------------------- |
| ![[git_compare_1.png]] | ![[git_compare_2.png]]    |
Как видно по картинкам, гит в каждой отдельной версии хранит образ всей системы. Для того, чтобы не плодить множество одинаковых файлов, для неизменившихся файлов хранятся ссылки на последнюю версию.





## Структура git

Локальный репозиторий хранится в папке .git
![[git_struct.png]]

Между рабочей директорией (IDE) и репозиторием существует прослойка из индекса - хранилища всех файлов, которые были затронуты изменениями. В .gitignore хранятся маски всех файлов, которые не попадают в индекс. Они оба хранятся локально в папке .git

![[git_indexing.png]]
### Ветвление

| Branches    | ![[git_branches.png]]         |
| ----------- | ----------------------------- |
| **Merging** | ![[git_branches_merging.png]] |


### Основные команды

| Команды при работе с git | ![[git_commands.png]] |
| ------------------------ | --------------------- |


## Рабочий процесс

### Обычные решения

***Git flow*** - стандартный подход в разработке ПО. Есть некоторая ветка master, которая релизится в прод, всё остальное используется для удобства разработки.
***forking flow*** - Это подход, используемый в opensource. Суть его в том, что если разработчик хочет улучшить продукт, то он создаёт ветку/вилку (fork), вносит изменения и отсылает PR одному из админов репозитория. Если фича проходит проверки, то она вливается в мастер. ^9de859

| Git flow              | forking flow              |
| --------------------- | ------------------------- |
| ![[git_flow_git.png]] | ![[gir_flow_forking.png]] |

***Зам.*** Эти методологии не подходят для DS, потому что аналитикам важна не финальная кодовая база, а извлечённые знания. Однако ноутбуки с экспериментами надо сохранять...

### Решение для аналитика данных
Data science lifecycle process (DSLP) - это методология, которая предполагает, что все необходимые данные уже извлечены и предобработаны. Позволяет сконцентрироваться на проверке гипотез. 

**Типы веток:**
1. master - главная ветка, в которой хранится продовая модель/данные
2. data - ветка для исследования/преобразования данных
3. experiment - сам проводимый эксперимент (связанный с проверкой некоторой гипотезы!)
	- Успешный эксперимент становится моделью, а успешная модель вливается в мастер
	- Неуспешный эксперимент остаётся висеть в истории гита, но не получает жизни
4. model - ветка, в которой строится модель. 


| master and data         | ![[git_dslp_data.png]]       |
| ----------------------- | ---------------------------- |
| **experiment (succes)** | ![[git_dslp_exp_succes.png]] |
| **experiment (failed)** | ![[git_dslp_exp_fail.png]]   |
| **model**               | ![[git_dslp_model.png]]      |

***Зам.*** Данный подход не сильно подходит, когда нужно много работать с данными и проверять много гипотез - репозиторий разрастается до неприличных размеров, а результаты экспериментов размазаны и перемешаны с ветками обработки данных (Если всё-таки данные оказались не идеально чистыми). *Решение - декомпозиция!*

#### Репозиторий исследователя
В этом репозитории хранятся все эксперименты. Под новое исследование создаётся своя ветка, которая открывается созданием ноутбука и закрывается отчётом о результатах исследования. Новых данных в ходе исследования не возникает! (только проверка гипотез)

***Зам.*** Данные получаются из внешнего хранилища. В идеале, для хранения данных также использовать свой git, например #tofill 

***Зам.*** На ревью первым делом смотрится не код, а итоги исследования

#### Репозиторий инженера
Ведётся по [[#^9de859|git flow]]. В этом репозитории хранятся все артефакты от исследований, производятся все изменения в данных. 

***Зам.*** Если какое-то исследование позволило улучшить продукт, то создаётся новая фича-ветка, в которой производится улучшение пайплайна обработки данных.

***Зам.*** Данные, полученные после внедрения фича-ветки в develop и из develop в master сохраняются в репозитории для данных и лишь после этого считаются безопасными для использования в новых экспериментах.

**Вывод**
Эта етодология позволяет сократить время на проведение исследования, так как нет необходимости интегрировать его с уже написанным кодом, а это избавляет от необходимости рефакторить и поддерживать все исследования сразу. Из-за изолированности исследования не зависят от общего кода, и их проще сделать воспроизводимыми. Правда появляется новая зависимость — данные, исследования очень сильно привязаны к определенной структуре и версии данных, что требует использовать специальные инструменты для работы с данными. Так же к минусам можно отнести что некоторые куски кода копируются из одного исследования в другое, что может привести к потенциальным ошибкам.

В пайплайн по обработке данных и построения моделей попадает только нужный код, основанный на успешных результатах исследований. Естественно поддержка пайплайна и добавление функциональности к пайплайну требует дополнительного времени на дизайн и рефакторинг кода для обработки данных. Но какие-то обновления пайплайна происходят не часто, так как туда идут только успешные результаты.