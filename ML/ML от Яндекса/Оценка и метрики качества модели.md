По сути, процесс обучение на выборке - это процесс переобучения модели на этой выборке. И чем ближе обучающая выборка к генеральной, тем точнее к истинному значению "переобучится" модель.

***Опр.*** Метрика - это #tofill 

***Опр.*** Оценка качества модели - это #tofill 

## Разбиение датасета
---
Датасет разбивается на 3 части:
1. Тренировочная (70%) - обучение модели
2. Валидационная (20%) - проверяем качество модели после каждого шага обучения. Используются .
3. Тестовая (10%) - проверка итоговой модели. Если нас устраивает качество, то модель заливается в прод, если нет, то обучение происходит с начала. Используются метрики качества модели.

## Cross validation
---
![[ModelEvaluation_CV.jpg]]

При кросс-валидации выборка разбивается на $n$ фолдов, затем происходит обучение модели на $(n-1)_i$ фолдах и оценивается качество на оставшемся *валидационном* фолде$\forall i \in\overline{[1, n]}$. 

Затем ищется средняя арифметическая ошибка по всем итерациям - она и считается конечной. Гиперпараметры тоже ищутся через среднее арифметическое (ЦПД говорит о том, что параметры стремятся к идеальным)

***Зам.*** Перед заливанием в прод нужно обучить модель на всём тренировочном + валидационном датасете с гиперпараметрами, выбранными на предыдущем шаге. Дальше тестовая выборка и прод.

## Метрики качества
---
Метрики качества нужны для определения итогового качества модели и используется для интерпретации человеком её жизнеспособности. #tofill 
### RMSE
---
$$L(y, \hat{y}) = \sqrt{\frac{1}{n}\sum^{n}_{i=1}(y - \hat{y})^2}$$
- $L'(y, \hat{y}) \in C^1 \subset R^+$
- Сильно штрафует за расхождение по одной из переменных
	- Допустим $y = (10, 10, 10)$, а $\hat{y}^{(1)} = (12, 5, 12)$, тогда $L^{(1)} = 11$, и при этом же если $\hat{y}^{(2)} = (13, 13, 13)$, то $L^{(2)} = 9 \implies$ $\frac{L^{(1)}}{L^{(2)}}= \frac{11}{9}$
- 