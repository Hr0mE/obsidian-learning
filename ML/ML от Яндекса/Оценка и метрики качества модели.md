По сути, процесс обучение на выборке - это процесс переобучения модели на этой выборке. И чем ближе обучающая выборка к генеральной, тем точнее к истинному значению "переобучится" модель.

***Опр.*** Метрика - это #tofill 

***Опр.*** Оценка качества модели - это #tofill 

## Разбиение датасета
---
Датасет разбивается на 3 части:
1. Тренировочная (70%) - обучение модели
2. Валидационная (20%) - проверяем качество модели после каждого шага обучения. Используются .
3. Тестовая (10%) - проверка итоговой модели. Если нас устраивает качество, то модель заливается в прод, если нет, то обучение происходит с начала. Используются метрики качества модели.

## Cross validation
---
![[ModelEvaluation_CV.jpg]]

При кросс-валидации выборка разбивается на $n$ фолдов, затем происходит обучение модели на $(n-1)_i$ фолдах и оценивается качество на оставшемся *валидационном* фолде$\forall i \in\overline{[1, n]}$. 

Затем ищется средняя арифметическая ошибка по всем итерациям - она и считается конечной. Гиперпараметры тоже ищутся через среднее арифметическое (ЦПД говорит о том, что параметры стремятся к идеальным)

***Зам.*** Перед заливанием в прод нужно обучить модель на всём тренировочном + валидационном датасете с гиперпараметрами, выбранными на предыдущем шаге. Дальше тестовая выборка и прод.

## Метрики качества
---
Метрики качества нужны для определения итогового качества модели и используется для интерпретации человеком её жизнеспособности. #tofill 
### RMSE
---
$$L(y, \hat{y}) = \sqrt{\frac{1}{n}\sum^{n}_{i=1}(y - \hat{y})^2}$$
- Переводит MSE в единицы измерения вектора $y$

### MAPE
---


### $R^2$
---
$$R^2 = 1 - \frac{\sum_{i=1}^n(y-\hat{y})^2}{\sum_{i=1}^n(y-\bar{y})^2}$$
Где:
- $\bar{y}$ - константное решение, предсказание средним арифметическим. *Baseline*.
- $R^2 \in (-\inf; 1]$, где $R^2 = 1$ - идеальное решение, $R^2(\bar{y}) = 0$

Зачем нужно?
-  Показывает, насколько построенная модель лучше/хуже baseline.

