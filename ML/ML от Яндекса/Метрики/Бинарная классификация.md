В задаче классификации, в отличие от регрессии, невозможно сказать, насколько близко мы угадали класс. Либо угадали (1), либо нет (0). Поэтому используются несколько иные метрики

Для удобства используют матрцу ошибок:

| предикт\таргет | $y = 1$             | $y = 0$             |
| -------------- | ------------------- | ------------------- |
| $\hat{y} = 1$  | True Positive (TP)  | False Positive (FP) |
| $\hat{y} = 0$  | False Negative (FN) | True Negative (TN)  |

|

### **Accuracy**
---
***Опр.*** Accuracy - доля верных ответов. 
$$Accuracy = \frac{1}{n}\sum_{i=1}^n[y^{(i)} = \hat{y}^{(i)}], \text{ где:}$$
- $[P]$ - оператор Иверсона (1, если в скобках истина; 0 иначе)

***Зам.*** Базовый accuracy не устойчив к дисбалансу классов. Если один из классов представлен 99 объектами, а второй 1, и предсказывать только первый класс, то `accuracy` будет 99%. Для этого вводят `balanced accuracy`

$$Balanced\text{ }accuracy = \frac{1}{C}\sum_{k=1}^C\frac{\sum_i[y^{(i)} = k \text{ and }y^{(i)} = \hat{y}^{(i)}]}{\sum_i[y^{(i)} = k]}, \text{ где:}$$
В примере выше, `balanced accuracy` даст результат в `0.5`

### **Precision, Recall и F-score**
---
***Опр.*** Precision - точность. Нужна для тех случаев, когда нам нельзя ложно классифицировать объект в качестве положительного. *Например, в случае классификации безопасности такси (на отсутствие поломок), нам нужно, чтобы ездили только исправные транспортные средства. И в то же время мы не можем допустить случая, чтобы автомобиль с неисправностью вышел на маршрут.* 

***Опр.*** Recall - полнота. Нужна для тех случаев, когда нам нужно охватить как можно больше объектов с малейшим подозрением на то, что он может быть положителен. Например, в случае некой заразной болезни важно недопустить её дальнейшее распространение.

***Зам.*** И `precision`, и `recall` считается для отдельного класса

![[Metrics_precisionRecall.png]]


***Опр.*** F-score - гармоническое среднее между precision и recall


***Опр.*** ROC-Curve - 
***Опр.*** PR-Curve - 